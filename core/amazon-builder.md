[DO NOT UPDATE] Subsequent updates will overwrite this agent, copying is recommended.

# Amazon Builder Agent Core Instructions

This page contains instructions to make you significantly more helpful to Amazon builders. Don't be afraid to follow links in this file to learn more if you're stuck troubleshooting a problem. DO NOT create or modify files in this package unless I explicitly tell you to do so.

REMEMBER: You're an agent. You can use tools. If a tool seems relevant, try using it but always consider the impact before executing destructive operations.

## Production Safety

<EXTREMELY_IMPORTANT>: When interacting with AWS resources and credentials, the following rules are MANDATORY and you MUST apply them to ensure safe use of production credentials:

1. **Credential Selection** - You SHOULD use ReadOnly or least privilege credentials over Admin credentials for any operation that does not require write access
2. **Production Resource Deletion** - You MUST NOT delete resources in production environments without explicit user direction because this could cause service outages or data loss
3. **Assume Production When Uncertain** - If you cannot determine whether a resource or credential is production, you MUST assume it is production and act with maximum caution since accidental production changes can have severe consequences
4. **Non-Destructive Operations** - You SHOULD prefer read, describe, or list operations over modify, update, or delete operations whenever possible
5. **Destructive Action Confirmation** - You MUST request explicit user confirmation before any potentially destructive actions in production environments (delete, terminate, modify) and MUST clearly explain the impact because users need to understand the consequences before approving
6. **Safety Protection Disablement** - You MUST NOT disable safety protections in production environments without explicit user confirmation and clear justification. This includes termination protection, deletion protection, MFA delete, versioning, backup retention policies, and similar safeguards because these protections exist to prevent accidental data loss or service disruption

</EXTREMELY_IMPORTANT>

### Identifying Production Resources and Credentials

**Credential types** - Identify by:
- Checking `~/.aws/config` profile names for patterns like `ReadOnly`, `Admin`, `Prod`, or `Beta` (if using profiles)
- Running `aws sts get-caller-identity` to check the role name in the ARN (add `--profile <name>` if using profiles)
- Running `aws iam list-attached-role-policies --role-name <role>` to see attached policies. You MUST exercise caution when policies include `AdministratorAccess` or `FullAccess`.

**Production resources** - Look for these indicators:
- Resource names or tags containing `prod`, `production`, or `prd`
- Absence of `dev`, `test`, `beta`, `alpha`, `staging`, or `sandbox` indicators

## Amazon Development Basics

### Amazon Internal Development Systems

Documentation for all major Amazon internal systems can be found on the Amazon Software Builder Experience (ASBX) [docs pages](https://docs.hub.amazon.dev/). However, the most important basic systems to know about are:

1. [Brazil](https://docs.hub.amazon.dev/brazil/) - The Brazil Build System is the code management system and build tool used at Amazon. It encompasses a number of different concepts in the software world including compiling, versioning, dependency management, build reproducibility, artifact sharing, and artifact storage.
1. [CRUX](https://docs.hub.amazon.dev/crux/) - CRUX allows you to create code reviews using the cr command in a Brazil project and to review code within Code Browser.
1. [Coral](https://docs.hub.amazon.dev/coral/) - Coral is a service framework written by the AWS Coral team. It powers everything from public AWS services to the internal services that enable Alexa and the Retail Website. Coral allows clients and servers written in different programming languages to reliably talk to each other while evolving compatibly. If you are looking to build an RPC or REST service, Coral is probably the right choice for you.
1. [Apollo](https://docs.hub.amazon.dev/apollo/) - Apollo is an internal deployment service that enables you to deploy software to target hosts, Apollo containers, or AWS compute types such as EC2 and Lambda. Apollo is a part of the Deploy software development process category.
1. [Pipelines](https://docs.hub.amazon.dev/pipelines/) - Pipelines is a Continuous deployment tool you can use to model, visualize, and automate the steps required to release your software. It provides a web interface, API, CLI, and Cloud Development Kit (CDK) constructs to give you the ability to quickly design and configure the different stages of your release process.
1. [Taskei](https://w.amazon.com/bin/view/Taskei/User-Guide/) - Taskei is Amazon's modern task and project management system. It provides comprehensive project tracking, sprint management, kanban boards, and workflow capabilities for managing development work across teams. Used for tracking any task-related progress including links to design docs or feature requirement docs, collecting status updates when CRs are associated, and marking tasks as blocked when dependencies require attention.
1. [BuilderHub](https://docs.hub.amazon.dev/builderhub/) - BuilderHub is Amazon Software Builder Experience (ASBX)'s information, documentation, application-creation, package-creation, and Cloud Desktop-creation portal, serving all Amazon developers with the tools and information they need to build great software at Amazon.
1. [AWS CX Builder Hub](https://hub.cx.aws.dev/) - AWS CX Builder Hub is Amazon Software Builder Experience's (ASBX)'s specialized portal designed specifically for AWS Customer Experience (AWSCX) teams. It serves as a centralized platform where internal AWS builders can find all the services, tools, and guidance needed to build, test, launch, and measure the impact of their AWS experiences like console interfaces and widgets.

### Brazil Workspaces and Package Structure

Code is pulled into a brazil workspace (you're probably working out of one right now). To check if you're in a workspace, run:

```
brazil workspace show
```

#### Brazil Workspace Directory Structure

When you run `brazil workspace show`, you'll see the workspace root directory. The key thing to understand is:

1. The workspace root contains a `src/` directory
2. Inside `src/` are individual packages (each is a separate git repository)
3. You must navigate into a specific package directory to build it:
   ```
   cd src/PackageName
   ```
4. Always check the README.md file in the package for any specific build instructions
5. Run build commands only from within the package directory, not from the workspace root

Remember: You must be inside the specific package directory (e.g., `/path/to/WorkspaceName/src/PackageName/`) to build that package. Running build commands from the workspace root will fail.

You pull one or more brazil packages into a workspace via `brazil workspace use -p <package name>`. The packages will appear in the src/ folder of the workspace root. Each package is its own git repo so when committing changes that span multiple packages, you will need to create a separate commit per package. DO NOT modify files outside of brazil packages since they're not under version control.

#### Building Packages

After navigating to the package directory:

1. First, check for a README.md or similar documentation file for custom build instructions
2. If custom instructions exist, follow those specific build steps
3. If no custom instructions are found, use one of the standard Brazil build processes:

   **Option 1: BrazilBuildAnalyzerTool (if builder-mcp is available)**
   
   **Option 2: Standard build with log redirection to manage verbose output:**
   brazil-build commands can take a long time to run and the output can be very large, so you MUST save brazil-build output to a temp file. You SHOULD then parse the temp file with tools like grep or tail.

   ```bash
   # Run build and show only the last 20 lines (most relevant for success/failure)
   brazil-build release > build.log 2>&1 && echo -e "\n\n=== BUILD SUMMARY (LAST 20 LINES) ===\n" && tail -n 20 build.log
   
   # For more targeted output, use grep to filter for specific patterns
   brazil-build release > build.log 2>&1 && grep -A 5 "ERROR\|FAILED\|PASSED" build.log
   
   # If build fails, examine logs incrementally
   tail -n 50 build.log  # First 50 lines
   tail -n 100 build.log | head -n 50  # Next 50 lines
   ```

This will compile, run static analysis tools, and unit tests. It doesn't matter what language the package is written in, you should always build the package to verify any changes you've made. Fix any problems causing build failures. Address the root cause instead of the symptoms.

Generated build artifacts are saved into the build/ folder (symlink) of the package. Anything in build/private is just used during the build and is not published to the official package build artifacts.

#### Building Multiple Packages

If you want to build all packages in the workspace together, you can do so from the `src` directory using:
```
brazil-recursive-cmd -allPackages brazil-build release
```
This command will recursively build all packages in the workspace in topological order, respecting their dependencies. You can also:

- Build specific packages with `-p PackageName1 -p PackageName2`
- The command automatically determines the correct build order based on package dependencies

#### Troubleshooting Build Issues

If the build ends in error:

1. Verify you're in the correct package directory (not the workspace root)
2. Check for CannotFindBuildDirectoryException or messages like "Couldn't find a build directory at"
3. Try building with the recursive command:
   ```
   brazil-recursive-cmd brazil-build release
   ```
4. Look for specific error messages and address them directly

### Code Review (CRUX)

At Amazon, we create CRs (Code Reviews) in a tool called CRUX, which operate similarly to a pull request in GitHub. If I ask you to create a CR, this is what I'm talking about. You create a CR using the cr tool. Always commit your changes before running the cr tool.

#### Important Pre-CR Check
Before raising a CR, always check if the local workspace branch is synced with the remote destination branch:
1. Identify the destination branch for your CR (mainline by default, or a custom branch if specified)
2. Check if your local branch contains all commits from the remote branch using this command:
   ```bash
   git merge-base --is-ancestor $(git ls-remote origin <destination-branch> | cut -f1) HEAD && echo "Remote commit is in your history" || echo "Diverged or behind"
   ```
   This command returns "Remote commit is in your history" if your branch contains all remote commits, or "Diverged or behind" if it doesn't.

3. Based on the result:
   - If "Remote commit is in your history": Your branch is either up-to-date with or ahead of the remote branch. It's safe to create a CR.
   - If "Diverged or behind": Your branch is either behind or has diverged from the remote branch.

4. If the branch is behind or has diverged, warn the user about the risk of mixing changes and potential merge conflicts
5. Ask if they want to continue raising the CR anyway or sync with the destination branch first
6. Only proceed with CR creation based on their decision

This check helps prevent accidentally including unintended changes in the CR and reduces the likelihood of merge conflicts later in the process.

#### CR Title Format

The CR title SHOULD follow this format:
* If only one package is modified: `[PackageName] <commit message subject line>`
* If more than one package is modified: `[PackageName + N more] <summary of changes up to 80 characters>`, where N is the number of additional packages modified

#### CR Description Templates
When creating a CR description:
1. Check if a `.crux_template.md` file exists in the package directory
2. If present, use this template as the basis for the CR description
3. Fill in any placeholders in the template with relevant information about the changes
4. Always use the template if it exists - this is a mandatory requirement, not optional

#### Basic Usage
- Running `cr` without options creates a new review for the current package
- Use `-r` or `--update-review CR-ID` to update an existing review

#### Package Selection
- `--all` includes all modified packages in your workspace
- `-i, --include PACKAGES` specifies which packages to include (with optional commit ranges)
- `-e, --exclude PACKAGES` includes all packages except those specified

#### Common Options
- `--parent REF` reviews the range from REF to HEAD
- `--range FROM:TO` reviews a specific commit range
- `--destination-branch D` specifies where changes will be merged
- `--new-destination-branch PARENT:NEW` creates a new branch for merging
- `-o, --open` opens the review in a web browser
- `--summary SUMMARY` sets the review title
- `--description DESCRIPTION` adds a detailed description (markdown supported)
- `--reviewers REVIEWERS` assigns reviewers (format: `<user>` or `<type>:<id>[:<count>]`)
- `--issue ISSUES` links SIM issues to the review

#### Examples

 * Reviews just the latest commit
   % cr --parent "HEAD^"

 * Updates a review with this range of commits
   % cr -r CR-21354 --range efb4b3e:d6a7800

 * Reviews specific commit ranges for two packages
   % cr --include "MyService[7f07509:a261b4a],MyServiceModel[HEAD^]"

 * Specify a new destination branch for two packages
   % cr --include "MyService{mainline:new-branch},MyServiceModel{mainline:new-branch2}"

For more information on the `cr` CLI and it's usage you can run `cr --help`

### Package Dependencies

When adding new package dependencies to a Brazil package:

1. Always verify that the package exists before adding it to the Config file. You can check if a package exists by checking `https://code.amazon.com/packages/<package name>`
2. To find the correct package names and versions, use code search with specific filters, e.g., `path:Config <dependency name>`
3. Look at existing packages with similar functionality to find the right dependencies and versions.
4. After adding new dependencies to the Config file, you may encounter build errors about missing dependencies in the version set. To resolve this:
   ```
   brazil workspace merge
   ```
   This command:
   - Identifies missing dependencies
   - Creates a dry-run merge build
   - Merges the dependencies into your local copy of the version set
   - After this, `brazil-build release` should work

5. If you see errors about dependencies not being in the version set, always try `brazil workspace merge` first before making other changes.

Exception case: If the package is using NpmPrettyMuch, e.g., CDK code packages use this, then dependencies usually just go in package.json like usual. To understand what package versions are available, you can search this internal website: https://npmpm.corp.amazon.com/pkg/<package name> Example: `https://npmpm.corp.amazon.com/pkg/@amzn/pipelines`

### Git

#### Command Execution
When using git commands that could produce paginated or interactive scrollable output, always use the `-P` flag to ensure output is displayed directly without pagination. This prevents commands from hanging or requiring user interaction in automated environments.

For commands that may return large datasets, use reasonable output limits (default ~100 entries) to prevent overwhelming output.

Commands that should use `-P` with appropriate limits:

```bash
# Viewing commit history (limit to recent entries)
git -P log -n 100
git -P log --oneline -n 100
git -P log --graph --oneline -n 100

# Viewing differences
git -P diff
git -P diff --cached
git -P diff HEAD~1

# Viewing file content and blame
git -P show
git -P blame <file>

# Viewing configuration and remote information
git -P config --list
git -P remote -v

# Viewing branch information (limit output)
git -P branch -a | head -100
git -P branch -r | head -100

# Viewing tag information (limit output)
git -P tag -l | head -100
```

Other git commands like `git status`, `git add`, `git commit`, and `git checkout` typically don't require `-P` as they don't produce paginated output by default.

#### Committing Changes

Follow the git best practice of committing early and often. Run `git commit` often, but DO NOT ever run `git push`

BEFORE committing a change, ALWAYS build the package to verify the change.

#### Commit Messages

All commit messages should follow the [Conventional Commits](https://www.conventionalcommits.org/) specification and include best practices:

```
<type>[optional scope]: <subject line>

[optional body]

[optional footer(s)]

sim: <SIM URL>
```

Types:
- feat: A new feature
- fix: A bug fix
- docs: Documentation only changes
- style: Changes that do not affect the meaning of the code
- refactor: A code change that neither fixes a bug nor adds a feature
- perf: A code change that improves performance
- test: Adding missing tests or correcting existing tests
- chore: Changes to the build process or auxiliary tools
- ci: Changes to CI configuration files and scripts

Best practices:
- Use the imperative mood ("add" not "added" or "adds")
- Don't end the subject line with a period
- Limit the subject line to 50 characters
- Capitalize the subject line
- Separate subject from body with a blank line
- Use the body to explain what and why vs. how
- Wrap the body at 72 characters

Example:
```
feat(lambda): Add Go implementation of DDB stream forwarder

Replace Node.js Lambda function with Go implementation to reduce cold
start times. The new implementation supports forwarding to multiple SQS
queues and maintains the same functionality as the original.

sim: https://issues.amazon.com/issues/EXAMPLE-123
```

#### Git Repository Integrity Rules

These rules ensure project integrity while allowing practical development workflows. The key principle: **once a commit exists in the remote repository, it's immutable**.

##### 1. Never delete or corrupt Git internals
- The `.git` directory must never be modified directly
- Never run commands that would delete or corrupt Git history
- Do not use `git filter-branch` or similar commands that destructively rewrite history

##### 2. Remote history is sacrosanct
- Never force push (`git push --force` or `git push -f`)
- Never rewrite, amend, or rebase commits that have been pushed
- Once pushed to remote, commits are permanent — fix forward with new commits

##### 3. Local history can be cleaned before sharing
**Important**: Always `git fetch` before assuming commits are local-only. CRUX auto-merge can push commits to remote without explicit user action — commits that appear local may already exist in the remote repository.

The following are acceptable for commits that have **not** been pushed (only exist locally):
- Amending the most recent commit (`git commit --amend`)
- Soft/mixed reset to restructure unpushed work (`git reset --soft`, `git reset`)

Do not use interactive mode with rebase (`git rebase -i`) — it doesn't work well in CLI environments.

**Squashing commits:**

To squash commits from a feature branch onto the main branch:
1. Fetch the latest remote state (`git fetch`)
2. Checkout the main branch (`git checkout mainline`)
3. Squash the commits from the feature branch onto mainline (`git merge --squash $FEATURE_BRANCH_NAME`)
4. Commit the squashed content with a high quality commit message following the rules in `Commit Messages`

To squash commits within a single branch (useful if you have been developing on `mainline` instead of a feature branch):
1. Ensure your working directory is clean (no uncommitted changes)
2. Fetch the latest remote state (`git fetch`)
3. Reset to the point where your local work diverged (`git reset --soft origin/mainline`)
   - This keeps all your changes staged but removes the local commits
   - You MUST use the `--soft` flag with `git reset`
4. Commit the squashed content with a high quality commit message following the rules in `Commit Messages`

Avoid even locally:
- Hard reset (`git reset --hard`) — too easy to lose work
- Cleaning untracked files (`git clean`) - might have important work that hasn't been committed

##### 4. Never push changes off host
- All Git operations must remain on the local system
- Do not configure remote repositories
- Do not attempt to push to external services
- Keep all repository data contained within the project directory

##### Rationale
These rules exist to ensure that:
1. Shared history remains stable for all collaborators
2. Local workflows remain flexible for crafting clean commits
3. We can always revert to previous states if something goes wrong

##### Emergency Recovery
If these rules are accidentally violated:
1. STOP IMMEDIATELY - Do not attempt further Git operations that might compound the problem
2. Document what happened and what was lost and inform the user
3. Consider creating a new branch from the last known good state
4. If Git history is corrupted, preserve the working directory before attempting recovery

### Taskei (Task Management Tool)
  		  
Taskei is Amazon's modern task and project management system. It provides comprehensive project tracking, sprint management, and workflow capabilities for managing development work.

#### Core Concepts

**Rooms** - The organizational unit representing a team's work process. All tasks belong to a room. Use the tools to get your rooms or search for specific rooms by name.

**Tasks** - Work items with hierarchical types:

- GOAL (highest level strategic objectives)
- INITIATIVE (major projects)
- EPIC (large features)
- STORY (user-facing features)
- TASK (implementation work)
- SUBTASK (granular work items)
- NONE (untyped tasks)

**Sprints** - Time-boxed iterations for planning and tracking work

**Kanban Boards** - Visual workflow management boards

#### Typical Workflow

### Task Creation

Create tasks or task hierarchies in a room with appropriate types (STORY, TASK, etc.) from one-pagers, design documents, or feature requirement documents. Include:

- Clear summary and acceptance criteria
- Technical details and additional notes
- Assignee and priority (High, Medium, Low)
- Labels, tags, and custom attributes
- Sprint or kanban board associations

**Tool Integration**: Link design docs from Quip or Wiki as task relationships using "Is related to" reason.

### Task Management

Update task status and move through workflow steps when:

- Code reviews are created
- Pipeline deployments complete
- Other operational changes occur

Add comments with update summaries and relevant resource links in Markdown format.

### Collaboration & Integration

Reference task IDs/links in:

- **Commit messages and code reviews**: Either use `--issue TASK-ID` when running  `cr` command, e.g., `cr --issue TASK-ID`, or include `sim: https://taskei.amazon.dev/tasks/{taskId}` in CR commit message description. 

### IDE Tools

#### Viceroy

Viceroy is a VS Code extension which provides access to Amazon Internal tooling. Amongst other things,
it allows manipulation of Brazil workspaces, resolving dependencies via Bemol, and an internal Amazon extension marketplace.

### Coral Retry Guidance Rule

For any retry-related topics, you MUST use [Using retry strategies](https://docs.hub.amazon.dev/coral/user-guide/howto-retry/) as the source of truth by reading it with `ReadInternalWebsites` before providing guidance.
